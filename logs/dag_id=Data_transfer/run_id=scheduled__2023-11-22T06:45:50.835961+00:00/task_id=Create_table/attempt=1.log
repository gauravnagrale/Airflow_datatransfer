[2023-11-22T07:16:01.922+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: Data_transfer.Create_table scheduled__2023-11-22T06:45:50.835961+00:00 [queued]>
[2023-11-22T07:16:01.945+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: Data_transfer.Create_table scheduled__2023-11-22T06:45:50.835961+00:00 [queued]>
[2023-11-22T07:16:01.945+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2023-11-22T07:16:01.946+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 3
[2023-11-22T07:16:01.947+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2023-11-22T07:16:01.982+0000] {taskinstance.py:1383} INFO - Executing <Task(PostgresOperator): Create_table> on 2023-11-22 06:45:50.835961+00:00
[2023-11-22T07:16:01.992+0000] {standard_task_runner.py:55} INFO - Started process 230 to run task
[2023-11-22T07:16:02.001+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'Data_transfer', 'Create_table', 'scheduled__2023-11-22T06:45:50.835961+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/data_transfer.py', '--cfg-path', '/tmp/tmp3qq4qe9h']
[2023-11-22T07:16:02.006+0000] {standard_task_runner.py:83} INFO - Job 3: Subtask Create_table
[2023-11-22T07:16:02.175+0000] {task_command.py:376} INFO - Running <TaskInstance: Data_transfer.Create_table scheduled__2023-11-22T06:45:50.835961+00:00 [running]> on host f71f95879a41
[2023-11-22T07:16:02.405+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Gaurav
AIRFLOW_CTX_DAG_ID=Data_transfer
AIRFLOW_CTX_TASK_ID=Create_table
AIRFLOW_CTX_EXECUTION_DATE=2023-11-22T06:45:50.835961+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-11-22T06:45:50.835961+00:00
[2023-11-22T07:16:02.435+0000] {base.py:71} INFO - Using connection ID 'source_db_***' for task execution.
[2023-11-22T07:16:02.451+0000] {sql.py:315} INFO - Running statement: 
        CREATE TABLE IF NOT EXISTS table1_users (
        title TEXT NOT NULL,
        firstname TEXT NOT NULL,
        lastname TEXT NOT NULL,
        gender TEXT NOT NULL,
        country TEXT NOT NULL,
        username TEXT NOT NULL,
        password TEXT NOT NULL,
        email TEXT NOT NULL,
        age INT NOT NULL
        )
        , parameters: None
[2023-11-22T07:16:02.470+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 94, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 295, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 320, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(table1_users, 2200) already exists.

[2023-11-22T07:16:02.498+0000] {taskinstance.py:1406} INFO - Marking task as UP_FOR_RETRY. dag_id=Data_transfer, task_id=Create_table, execution_date=20231122T064550, start_date=20231122T071601, end_date=20231122T071602
[2023-11-22T07:16:02.530+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 3 for task Create_table (duplicate key value violates unique constraint "pg_type_typname_nsp_index"
DETAIL:  Key (typname, typnamespace)=(table1_users, 2200) already exists.
; 230)
[2023-11-22T07:16:02.572+0000] {local_task_job.py:164} INFO - Task exited with return code 1
[2023-11-22T07:16:02.640+0000] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
